# Talon Global Configuration â€” OpenClaw Gateway
# Generated by: talon init --pack openclaw
#
# This config runs Talon as an OpenAI-compatible gateway in front of OpenClaw.
# OpenClaw sends every chat request to Talon; Talon authenticates the caller,
# scans for PII, enforces cost/model limits, forwards to OpenAI, and writes
# an audit record.
#
# Quick start:
#   1. Set your real OpenAI key:  talon secrets set openai-api-key "sk-..."
#   2. Start the gateway:         talon serve --gateway
#   3. Point OpenClaw at:         http://localhost:8080/v1/proxy/openai
#      with API key:              talon-gw-openclaw-001
#   4. Check audit trail:         talon audit list

llm_provider: openai
log_level: info
log_format: console

evidence:
  type: sqlite
  path: ~/.talon/evidence.db

secrets_key_env: TALON_SECRETS_KEY

tenants:
  - id: default
    display_name: Default Tenant
    budgets:
      daily: 50.0
      monthly: 1000.0
    rate_limit: 60

gateway:
  enabled: true
  listen_prefix: "/v1/proxy"
  mode: "shadow"

  providers:
    openai:
      enabled: true
      secret_name: "openai-api-key"
      base_url: "https://api.openai.com"
      allowed_models: ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"]

  # Caller api_key = token OpenClaw sends (Authorization: Bearer ...). Not TALON_SECRETS_KEY.
  callers:
    - name: "openclaw-main"
      api_key: "talon-gw-openclaw-001"
      tenant_id: "default"
      team: "engineering"
      allowed_providers: ["openai"]
      policy_overrides:
        max_daily_cost: 25.00
        max_monthly_cost: 500.00
        pii_action: "redact"
        allowed_models: ["gpt-4o", "gpt-4o-mini"]

  default_policy:
    default_pii_action: "warn"
    # warn = audit PII in evidence (recommended for LLM-generated content).
    # Escalate to "redact" or "block" for stricter environments.
    response_pii_action: "warn"
    max_daily_cost: 100.00
    max_monthly_cost: 2000.00
    require_caller_id: true
    log_prompts: true
    log_responses: false
    # Attachment scanning: scans base64-encoded files (PDF, TXT, CSV, HTML)
    # in LLM API requests for PII and prompt injection.
    attachment_policy:
      action: "warn"            # block | strip | warn | allow
      injection_action: "warn"  # block | strip | warn
      max_file_size_mb: 10

  rate_limits:
    global_requests_per_min: 300
    per_caller_requests_per_min: 60

  timeouts:
    connect_timeout: 10s
    request_timeout: 120s
    stream_idle_timeout: 60s
