# OpenClaw + Talon primer â€” OpenAI only.
# One provider (OpenAI), one caller (openclaw-main). Talon governs every request before forwarding.

gateway:
  enabled: true
  listen_prefix: "/v1/proxy"
  mode: "enforce"

  providers:
    openai:
      enabled: true
      secret_name: "openai-api-key"
      base_url: "https://api.openai.com"
      allowed_models: ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"]

  callers:
    # api_key below is the CALLER TOKEN (what OpenClaw sends). Not TALON_SECRETS_KEY.
    # TALON_SECRETS_KEY encrypts the vault; this key only identifies the caller.
    - name: "openclaw-main"
      api_key: "talon-gw-openclaw-001"
      tenant_id: "default"
      team: "engineering"
      allowed_providers: ["openai"]
      policy_overrides:
        max_daily_cost: 25.00
        max_monthly_cost: 500.00
        pii_action: "redact"
        allowed_models: ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"]

  default_policy:
    default_pii_action: "warn"
    response_pii_action: "redact"
    max_daily_cost: 100.00
    max_monthly_cost: 2000.00
    require_caller_id: true
    log_prompts: true
    log_responses: false

  rate_limits:
    global_requests_per_min: 300
    per_caller_requests_per_min: 60

  timeouts:
    connect_timeout: 10s
    request_timeout: 120s
    stream_idle_timeout: 60s

# NOTE: Per-tool PII policies (tool_policies) and circuit breaker settings are
# configured in the agent .talon.yaml policy (agent.talon.yaml), not in the
# gateway config. The gateway governs LLM API traffic; the agent runner governs
# tool execution. See agent.talon.yaml for:
#   tool_policies:      per-tool, per-argument PII actions (allow|audit|redact|block)
#   rate_limits:
#     circuit_breaker_threshold: 5
#     circuit_breaker_window: "60s"
